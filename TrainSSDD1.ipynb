{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Masukan seluruh library\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import random\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import io\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "metadata": {
        "id": "D0vAZRQpf3-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDwr6LMDyC6Q",
        "outputId": "37c7011b-8033-437b-e658-e36b52e188be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "/content/gdrive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "#Import Goolge Drive ke Collab\n",
        "drive.mount('/content/gdrive')\n",
        "%cd /content/gdrive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#UnZip data yang ada di goolge drive\n",
        "with ZipFile('/content/gdrive/MyDrive/data/raw_data.zip', 'r') as zipObj:\n",
        "  zipObj.extractall('/content/gdrive/MyDrive/data')"
      ],
      "metadata": {
        "id": "-8jBgiPrRdmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Buat direktori data/split_data dan jalankan perintah split train test\n",
        "raw_data_path = \"/content/gdrive/MyDrive/data/raw_data/images\"\n",
        "train_data_path = \"/content/gdrive/MyDrive/data/split_data/train\"\n",
        "test_data_path = \"/content/gdrive/MyDrive/data/split_data/test\"\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/data/split_data/\"):\n",
        "  os.mkdir(\"/content/gdrive/MyDrive/data/split_data/\")\n",
        "\n",
        "try:\n",
        "  shutil.rmtree(train_data_path)\n",
        "  shutil.rmtree(test_data_path)\n",
        "except:\n",
        "  pass\n",
        "\n",
        "os.mkdir(train_data_path)\n",
        "os.mkdir(test_data_path)\n",
        "\n",
        "total_files = glob.glob(raw_data_path + \"/*.jpg\")\n",
        "print(\"Sample file = \", total_files[0])\n",
        "print(\"Total file = \", len(total_files))\n",
        "\n",
        "indices = list(range(len(total_files)))\n",
        "train_indices = random.sample(indices, k = int(len(total_files)*0.9))\n",
        "print(\"Total train file = \", len(train_indices))\n",
        "\n",
        "for i in indices:\n",
        "\n",
        "    if (i in train_indices):\n",
        "        # Copy to train\n",
        "        shutil.copy(total_files[i], train_data_path + total_files[i].replace(raw_data_path,\"\"))\n",
        "        shutil.copy(total_files[i].replace(\"images\",\"labels\").replace(\".jpg\",\".xml\"),\n",
        "                    train_data_path + total_files[i].replace(raw_data_path, \"\").replace(\".jpg\",\".xml\"))\n",
        "    else:\n",
        "        # Copy to test\n",
        "        shutil.copy(total_files[i], test_data_path + total_files[i].replace(raw_data_path, \"\"))\n",
        "        shutil.copy(total_files[i].replace(\"images\", \"labels\").replace(\".jpg\", \".xml\"),\n",
        "                    test_data_path + total_files[i].replace(raw_data_path, \"\").replace(\".jpg\",\".xml\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6irQ3in12lHi",
        "outputId": "9e9bfc22-8015-40c7-b2f1-8a40947d5a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample file =  /content/gdrive/MyDrive/data/raw_data/images/10_jpg.rf.2458551329cd7f49d79564e174a2dc8a.jpg\n",
            "Total file =  1476\n",
            "Total train file =  1328\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#3.Konversi label XML ke CSV. File CSV disimpan di folder split_data\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(os.path.join(path, '*.xml')):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            bndbox = member.find('bndbox')\n",
        "            if bndbox is not None and all(bndbox.find(coord) is not None for coord in ['xmin', 'ymin', 'xmax', 'ymax']):\n",
        "                value = (root.find('filename').text,\n",
        "                         int(root.find('size').find('width').text),\n",
        "                         int(root.find('size').find('height').text),\n",
        "                         member.find('name').text,\n",
        "                         int(bndbox.find('xmin').text),\n",
        "                         int(bndbox.find('ymin').text),\n",
        "                         int(bndbox.find('xmax').text),\n",
        "                         int(bndbox.find('ymax').text))\n",
        "                xml_list.append(value)\n",
        "            else:\n",
        "                print(f\"Skipping {xml_file}, as it doesn't match the expected structure.\")\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "for directory in ['train','test']:\n",
        "        image_path = os.path.join('/content/gdrive/MyDrive/data/split_data/{}'.format(directory))\n",
        "        xml_df = xml_to_csv(image_path)\n",
        "        xml_df.to_csv('/content/gdrive/MyDrive/data/split_data/{}_labels.csv'.format(directory), index=None)\n",
        "        print('Successfully converted xml to csv.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuDQU62_3yeL",
        "outputId": "fcdf07ad-d354-4043-84ed-d8ed4685a98f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully converted xml to csv.\n",
            "Successfully converted xml to csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Unduh TF Object Detection APi ke dalam folder model\n",
        "%cd /content/gdrive/MyDrive\n",
        "!git clone https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO0-eIRH4QPT",
        "outputId": "c816b13f-94f1-426c-d36d-3fd627bc514e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive\n",
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 97295, done.\u001b[K\n",
            "remote: Counting objects: 100% (575/575), done.\u001b[K\n",
            "remote: Compressing objects: 100% (288/288), done.\u001b[K\n",
            "remote: Total 97295 (delta 341), reused 474 (delta 283), pack-reused 96720\u001b[K\n",
            "Receiving objects: 100% (97295/97295), 612.92 MiB | 14.46 MiB/s, done.\n",
            "Resolving deltas: 100% (70753/70753), done.\n",
            "Updating files: 100% (3705/3705), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Kompilasi proto -\n",
        "# Protocol Buffers (Protobuf) adalah format data lintas platform sumber terbuka dan gratis yang digunakan untuk membuat serial data terstruktur.\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6UO3NVW4dtk",
        "outputId": "5b313266-97d9-4cab-f476-c77f37c30beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Instal API\n",
        "%cd /content/drive/MyDrive/models/research\n",
        "!cp object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8n39Lit41Cj",
        "outputId": "f0b8e433-cce1-4447-f92f-c544debba441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/models/research'\n",
            "/content/gdrive/MyDrive/models/research\n",
            "Processing /content/gdrive/MyDrive/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.5/14.5 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.10)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.16.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.15.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2024.5.15)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.25.2)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.6.14)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.0.80)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.1.99)\n",
            "Collecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.16.1)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.16.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow~=2.16.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow-2.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (589.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-keras>=2.16.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2024.1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.64.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.19.2)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.0.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (24.0)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (670 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.0/670.0 kB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading redis-5.0.4-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.0/252.0 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.11.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.6)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.51.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object-detection==0.1) (0.37.0)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.18.1)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2024.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.4)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object-detection==0.1) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.7)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Collecting h5py>=3.10.0 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading h5py-3.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras (from object-detection==0.1)\n",
            "  Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object-detection==0.1) (13.7.1)\n",
            "Collecting namex (from keras->object-detection==0.1)\n",
            "  Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
            "Collecting optree (from keras->object-detection==0.1)\n",
            "  Downloading optree-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.6.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object-detection==0.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object-detection==0.1) (2.16.1)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.7.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.15.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.43.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.4.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.18.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.63.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object-detection==0.1) (0.1.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (3.0.3)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow~=2.16.1->tf-models-official>=2.5.1->object-detection==0.1) (2.1.5)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697356 sha256=2c13a306e1e9bbce6626b07cecbc2856dd89b0d6543bc598a5d7910c8cb04957\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p5jabt6i/wheels/3d/67/ca/94b29b20419b65343290089e8733ac489446a612bd57458c73\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=3e26c390a2b857ba1f7291f5646337aba4e1989c9d66ec0c4e7adf43b9838d55\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31405 sha256=89d3368e16745c6884ff894f26749be4539938ef2797474127f1c07e4006bec6\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78541 sha256=0e88335daff2690add3b1bd7892ee57ed23a7363cf92137097ff92753e11d79d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=45924499b1fc285dee23598ff2c18e53c70ee5222eb903192e1f7a6076580017\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=b2a36842ccc08c023683e33ccb37d11a6ac2e4986bbd3a567a3a4149e2eed0dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=1d6ab3a575eee6e39b165c4b63b838b0eb7c97b2a138c835baec8abac198ecfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=167353c5bc2cf92e606e05544da799a942ceafee48508c04dc39847c7a276a8a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n",
            "Installing collected packages: pyjsparser, namex, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, redis, pyparsing, portalocker, orjson, optree, objsize, ml-dtypes, js2py, immutabledict, h5py, fasteners, fastavro, dnspython, dill, colorama, avro-python3, tensorboard, sacrebleu, pymongo, hdfs, seqeval, lvis, keras, tensorflow, apache-beam, tf-keras, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.2\n",
            "    Uninstalling pyparsing-3.1.2:\n",
            "      Successfully uninstalled pyparsing-3.1.2\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.2.0\n",
            "    Uninstalling ml-dtypes-0.2.0:\n",
            "      Successfully uninstalled ml-dtypes-0.2.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.9.0\n",
            "    Uninstalling h5py-3.9.0:\n",
            "      Successfully uninstalled h5py-3.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.15.1\n",
            "    Uninstalling tf_keras-2.15.1:\n",
            "      Successfully uninstalled tf_keras-2.15.1\n",
            "Successfully installed apache-beam-2.56.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.6.1 docopt-0.6.2 fastavro-1.9.4 fasteners-0.19 h5py-3.11.0 hdfs-2.7.3 immutabledict-4.2.0 js2py-0.74 keras-3.3.3 lvis-0.5.3 ml-dtypes-0.3.2 namex-0.0.8 object-detection-0.1 objsize-0.7.0 optree-0.11.0 orjson-3.10.3 portalocker-2.8.2 pyjsparser-2.7.1 pymongo-4.7.2 pyparsing-2.4.7 redis-5.0.4 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.16.2 tensorflow-2.16.1 tensorflow-model-optimization-0.8.0 tensorflow-text-2.16.1 tensorflow_io-0.37.0 tf-keras-2.16.0 tf-models-official-2.16.0 zstandard-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Test API\n",
        "!python object_detection/builders/model_builder_tf2_test.py"
      ],
      "metadata": {
        "id": "vDDQhQ2E43wV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642b6941-08d0-48f4-f346-7c106343d36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-06-02 14:54:22.008959: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-02 14:54:23.332767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/models/research/object_detection/builders/model_builder_tf2_test.py\", line 24, in <module>\n",
            "    from object_detection.builders import model_builder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/model_builder.py\", line 26, in <module>\n",
            "    from object_detection.builders import hyperparams_builder\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/hyperparams_builder.py\", line 27, in <module>\n",
            "    from object_detection.core import freezable_sync_batch_norm\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/core/freezable_sync_batch_norm.py\", line 20, in <module>\n",
            "    class FreezableSyncBatchNorm(tf.keras.layers.experimental.SyncBatchNormalization\n",
            "AttributeError: module 'keras._tf_keras.keras.layers' has no attribute 'experimental'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. CSV to TFRecord. With help from MiAI git hub\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "!git clone https://github.com/thangnch/MiAI_SSD_TF2\n",
        "!cp MiAI_SSD_TF2/generate_tfrecord.py .\n",
        "!cp MiAI_SSD_TF2/label_map.txt /content/gdrive/MyDrive/data\n",
        "\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/data/tfrecord_data/\"):\n",
        "  os.mkdir(\"/content/gdrive/MyDrive/data/tfrecord_data/\")\n",
        "\n",
        "!python generate_tfrecord.py --image_dir=/content/gdrive/MyDrive/data/split_data/train --csv_input=/content/gdrive/MyDrive/data/split_data/train_labels.csv --output_path=/content/gdrive/MyDrive/data/tfrecord_data/train.record\n",
        "!python generate_tfrecord.py --image_dir=/content/gdrive/MyDrive/data/split_data/test --csv_input=/content/gdrive/MyDrive/data/split_data/test_labels.csv --output_path=/content/gdrive/MyDrive/data/tfrecord_data/test.record\n"
      ],
      "metadata": {
        "id": "xkkPB2yJ5V2M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73e69ca-89fe-4d92-8d34-84b71b9c4a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n",
            "fatal: destination path 'MiAI_SSD_TF2' already exists and is not an empty directory.\n",
            "2024-06-02 15:37:45.740604: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-02 15:37:46.940273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-06-02 15:37:48.778681: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-02 15:37:48.851120: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-02 15:37:48.851596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Successfully created the TFRecords: /content/gdrive/MyDrive/data/tfrecord_data/train.record\n",
            "2024-06-02 15:38:00.915868: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-02 15:38:02.295049: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-06-02 15:38:04.141291: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-02 15:38:04.206633: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2024-06-02 15:38:04.206973: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Successfully created the TFRecords: /content/gdrive/MyDrive/data/tfrecord_data/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Download pretrain and config\n",
        "if not os.path.exists(\"/content/gdrive/MyDrive/pretrained\"):\n",
        "  os.mkdir(\"/content/gdrive/MyDrive/pretrained\")\n",
        "\n",
        "%cd /content/gdrive/MyDrive/pretrained\n",
        "!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "# Unzip\n",
        "!tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
        "\n",
        "# Config pipeline.config, label_map.txt if needed"
      ],
      "metadata": {
        "id": "Hr7hm9ha6TpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e755de1-abf9-4d78-f72f-e2631f700a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/pretrained\n",
            "--2024-06-02 15:38:27--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.250.4.207, 172.253.118.207, 74.125.200.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.250.4.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.2’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  9.91MB/s    in 2.0s    \n",
            "\n",
            "2024-06-02 15:38:31 (9.91 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz.2’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload label file object-detection.txt to data folder\n",
        "%cd /content/gdrive/MyDrive/models\n",
        "!pip install -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt\n",
        "!pip install --upgrade opencv-python"
      ],
      "metadata": {
        "id": "D3CcUUaj77XM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b866a0c8-afcf-4b39-9e36-4090be012b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 2)) (0.37.0)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 3)) (0.23.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 5)) (4.9.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 7)) (2.0.3)\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 9)) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 10)) (1.11.4)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 11)) (0.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 12)) (6.0.1)\n",
            "Requirement already satisfied: lvis in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 13)) (0.5.3)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from -r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 14)) (0.5.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (1.64.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.37.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (1.25.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from tensorflow_addons->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 3)) (2.13.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 7)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 7)) (2024.1)\n",
            "Requirement already satisfied: Cython>=0.29.12 in /usr/local/lib/python3.10/dist-packages (from lvis->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 13)) (3.0.10)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 13)) (4.9.0.80)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.43.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow->-r /content/gdrive/MyDrive/models/research/MiAI_SSD_TF2/setup.txt (line 1)) (0.1.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.9.0.80)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.exists('/content/gdrive/MyDrive/models/research')\n",
        "os.path.exists('/content/gdrive/MyDrive/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config')\n",
        "os.path.exists('/content/gdrive/MyDrive/output_model')\n",
        "\n",
        "print(os.path.exists('/content/gdrive/MyDrive/models/research'))\n",
        "print(os.path.exists('/content/gdrive/MyDrive/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config'))\n",
        "print(os.path.exists('/content/gdrive/MyDrive/output_model'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUsF94Mdm4tx",
        "outputId": "2e74762b-2d86-43dc-c837-6fdd9b4da880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "%cp /content/gdrive/MyDrive/models/research/object_detection/model_main_tf2.py ."
      ],
      "metadata": {
        "id": "K1vFHj-68Iut",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a9b223-8ca2-43be-f0d1-7b46684214fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/models/research\n",
            "2024-06-02 15:41:52.152203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-02 15:41:53.635207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/gdrive/MyDrive/models/research/model_main_tf2.py\", line 31, in <module>\n",
            "    from object_detection import model_lib_v2\n",
            "  File \"/content/gdrive/MyDrive/models/research/object_detection/model_lib_v2.py\", line 30, in <module>\n",
            "    from object_detection import inputs\n",
            "  File \"/content/gdrive/MyDrive/models/research/object_detection/inputs.py\", line 24, in <module>\n",
            "    from tensorflow.compat.v1 import estimator as tf_estimator\n",
            "ImportError: cannot import name 'estimator' from 'tensorflow.compat.v1' (/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train\n",
        "!python model_main_tf2.py \\\n",
        "--pipeline_config_path=/content/gdrive/MyDrive/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--model_dir=/content/gdrive/MyDrive/output_model --alsologtostderr --num_train_steps=1000"
      ],
      "metadata": {
        "id": "_tXr0FXHNylz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export model\n",
        "%cd /content/gdrive/MyDrive/models/research\n",
        "%cp /content/gdrive/MyDrive/models/research/object_detection/exporter_main_v2.py .\n",
        "\n",
        "!python exporter_main_v2.py \\\n",
        "--trained_checkpoint_dir=/content/gdrive/MyDrive/output_model \\\n",
        "--pipeline_config_path=/content/gdrive/MyDrive/pretrained/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config \\\n",
        "--output_directory=/content/gdrive/MyDrive/export_model"
      ],
      "metadata": {
        "id": "yQc6i425BYJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io\n",
        "import os\n",
        "import scipy.misc\n",
        "import numpy as np\n",
        "import six\n",
        "import time\n",
        "import glob\n",
        "from IPython.display import display\n",
        "\n",
        "from six import BytesIO\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "#Load model\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.saved_model.load(\"/content/gdrive/MyDrive/export_model/saved_model\")"
      ],
      "metadata": {
        "id": "YPOw7SduBnzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Các hàm inference\n",
        "\n",
        "import cv2\n",
        "def run_inference_for_single_image(model, image):\n",
        "\n",
        "  image = np.asarray(image)\n",
        "  input_tensor = tf.convert_to_tensor(image)\n",
        "  input_tensor = input_tensor[tf.newaxis,...]\n",
        "\n",
        "  model_fn = model.signatures['serving_default']\n",
        "  output_dict = model_fn(input_tensor)\n",
        "\n",
        "  num_detections = int(output_dict.pop('num_detections'))\n",
        "  output_dict = {key:value[0, :num_detections].numpy()\n",
        "                 for key,value in output_dict.items()}\n",
        "  output_dict['num_detections'] = num_detections\n",
        "  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\n",
        "\n",
        "  if 'detection_masks' in output_dict:\n",
        "    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
        "              output_dict['detection_masks'], output_dict['detection_boxes'],\n",
        "               image.shape[0], image.shape[1])\n",
        "    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\n",
        "                                       tf.uint8)\n",
        "    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\n",
        "\n",
        "  return output_dict\n",
        "\n",
        "def load_image_into_numpy_array(path):\n",
        "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
        "  image = Image.open(BytesIO(img_data))\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)"
      ],
      "metadata": {
        "id": "MjNtRom3CTu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/MyDrive/models/research\n",
        "category_index = label_map_util.create_category_index_from_labelmap(\"/content/gdrive/MyDrive/data/label_map.txt\", use_display_name=True)\n",
        "\n",
        "image_path = '/content/gdrive/MyDrive/data/split_data/train/2.jpg'\n",
        "image_np = load_image_into_numpy_array(image_path)\n",
        "print(\"Done load image \")\n",
        "image_np = cv2.resize(image_np, dsize=None, fx=0.2, fy=0.2)\n",
        "output_dict = run_inference_for_single_image(model, image_np)\n",
        "print(\"Done inference\")\n",
        "vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "    image_np,\n",
        "    output_dict['detection_boxes'],\n",
        "    output_dict['detection_classes'],\n",
        "    output_dict['detection_scores'],\n",
        "    category_index,\n",
        "    instance_masks=output_dict.get('detection_masks_reframed', None),\n",
        "    use_normalized_coordinates=True,\n",
        "    line_thickness=8)\n",
        "print(\"Done draw on image \")\n",
        "display(Image.fromarray(image_np))"
      ],
      "metadata": {
        "id": "RiNTDEAVCbbP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}